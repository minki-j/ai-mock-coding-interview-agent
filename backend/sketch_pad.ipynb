{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Docker container\n",
    "run this command to access its terminal\n",
    "```bash\n",
    "docker exec -it ai-mock-coding-interview-agent-fastapi-1 /bin/bash\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.main_graph import main_graph\n",
    "id = \"6734f462996d5ea7277bd903\"\n",
    "config = {\"configurable\": {\"thread_id\": id}, \"recursion_limit\": 100}\n",
    "state = main_graph.get_state(config).values\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_to_single_line(code_string: str) -> str:\n",
    "    # Replace tabs/spaces with \\t and newlines with \\n\n",
    "    lines = code_string.split(\"\\n\")\n",
    "    # Process each line to convert leading spaces/tabs to \\t\n",
    "    processed_lines = []\n",
    "    for line in lines:\n",
    "        # Count leading spaces (assuming 4 spaces = 1 tab)\n",
    "        leading_spaces = len(line) - len(line.lstrip())\n",
    "        tab_count = leading_spaces // 4\n",
    "        # Replace the leading spaces with \\t characters\n",
    "        processed_line = \"\\t\" * tab_count + line.lstrip()\n",
    "        processed_lines.append(processed_line)\n",
    "\n",
    "    # Join with literal \\n\n",
    "    return \"\\\\n\".join(processed_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from markdownify import markdownify\n",
    "\n",
    "path = \"/Users/minkijung/Documents/2PetProjects/ai-mock-coding-interview-agent/backend/db/leetcode/scraped_data/longest-common-prefix.json\"\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "solution_md = markdownify(data[\"solution\"][\"content\"])\n",
    "content_md = markdownify(data[\"content\"])\n",
    "\n",
    "data[\"solution_md\"] = solution_md\n",
    "data[\"content_md\"] = content_md\n",
    "\n",
    "with open(path, \"w\") as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a function that uses the first element of the list as a reference.\n",
    "2. Iteratively check if the first n characters of the reference are included in all other elements.\n",
    "3. Increase n until finding the longest common prefix.\n",
    "4. Add an assertion to check for empty elements in the array.\n",
    "5. Consider handling special characters as an edge case.\n",
    "6. Implement the solution and analyze time complexity during coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interview_question': str,\n",
       " 'interview_solution': str,\n",
       " 'code_editor_state': str,\n",
       " 'debugging_record': list[str]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class DebuggingAgentPrivateState(BaseModel):\n",
    "    interview_question: str = Field(default=\"\")\n",
    "    interview_solution: str = Field(default=\"\")\n",
    "    code_editor_state: str = Field(default=\"\")\n",
    "\n",
    "    debugging_record: list[str] = Field(default=[])\n",
    "\n",
    "state = DebuggingAgentPrivateState()\n",
    "state.__annotations__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# populate prep_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "with open(\n",
    "    \"/Users/minkijung/Documents/2PetProjects/ai-mock-coding-interview-agent/backend/db/leetcode.json\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    allquestions = json.load(f)\n",
    "\n",
    "id_title_dict = {}\n",
    "for question in allquestions:\n",
    "    id_title_dict[question[\"title\"].replace(\" \", \"\").replace(\"-\", \"\").replace(\"_\", \"\").lower()] = question[\"id\"]\n",
    "\n",
    "print(id_title_dict[\"twosum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import random\\nimport string\\nimport unittest\\n\\nfrom hypothesis import given\\nfrom hypothesis.strategies import text\\n\\n\\nclass Test(unittest.TestCase):\\n    def test_1(self):\\n        solution = Solution()\\n        self.assertEqual(solution.findTheDifference(\"abcd\", \"abcde\"), \"e\")\\n\\n    @given(text())\\n    def test_random(self, s):\\n        solution = Solution()\\n        random_letter = random.choice(string.ascii_letters)\\n        t = list(s + random_letter)\\n        random.shuffle(t)\\n        t = \"\".join(t)\\n        self.assertEqual(solution.findTheDifference(s, t), random_letter)\\n\\n\\nif __name__ == \"__main__\":\\n    unittest.main()\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "prep_code_dict = {}\n",
    "test_code_dict = {}\n",
    "\n",
    "path = \"/Users/minkijung/Documents/2PetProjects/ai-mock-coding-interview-agent/backend/db/prep\"\n",
    "for id in os.listdir(path):\n",
    "    if \"test\" in id:\n",
    "        file_path = os.path.join(path, id)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            test_code_dict[id.split(\"_\")[0]] = f.read()\n",
    "\n",
    "    file_path = os.path.join(path, id)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = f.read()\n",
    "        prep_code_dict[id.split(\".\")[0]] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> 3sum\n",
      "==>> longestpalindromicsubstring\n",
      "==>> validparentheses\n",
      "==>> nextpermutation\n",
      "==>> binarytreeinordertraversal\n",
      "==>> reverseinteger\n",
      "==>> containerwithmostwater\n",
      "==>> mergeintervals\n",
      "==>> addtwonumbers\n",
      "==>> longestsubstringwithoutrepeatingcharacters\n",
      "==>> palindromenumber\n",
      "==>> longestcommonprefix\n",
      "==>> mergesortedarray\n",
      "==>> 4sum\n",
      "==>> twosum\n",
      "==>> medianoftwosortedarrays\n",
      "==>> insertinterval\n",
      "==>> swapnodesinpairs\n",
      "==>> lengthoflastword\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/minkijung/Documents/2PetProjects/ai-mock-coding-interview-agent/backend/db/leetcode/refined_data\"\n",
    "new_path = \"/Users/minkijung/Documents/2PetProjects/ai-mock-coding-interview-agent/backend/db/leetcode/complete_data\"\n",
    "\n",
    "for question in os.listdir(path):\n",
    "    title = question.split(\".\")[0].replace(\" \", \"\").replace(\"-\", \"\").replace(\"_\", \"\").lower()\n",
    "    id = id_title_dict.get(title)\n",
    "\n",
    "    prep_code = prep_code_dict.get(id)\n",
    "    if prep_code:\n",
    "        print(f\"==>> {title}\")\n",
    "        with open(os.path.join(path, question), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        data[\"prep_code\"] = prep_code\n",
    "        data[\"test_code\"] = test_code_dict.get(id)\n",
    "\n",
    "        if data.get(\"solution_md\"):\n",
    "            with open(os.path.join(new_path, question), \"w\") as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "        else:\n",
    "            with open(os.path.join(path, question), \"w\") as f:\n",
    "                json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markdownify import markdownify\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "new_path = \"/Users/minkijung/Documents/2PetProjects/ai-mock-coding-interview-agent/backend/db/leetcode/complete_data\"\n",
    "\n",
    "for question in os.listdir(new_path):\n",
    "    with open(os.path.join(new_path, question), \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    data[\"content_md\"] = markdownify(data[\"content\"]).replace(\"\\n\\n\\u00a0\\n\\n\", \"\")\n",
    "    solution = data[\"solution\"][\"content\"]\n",
    "    solution = (\n",
    "        solution.replace('<iframe src=\"\\n', \"\")\n",
    "        .replace('\"></iframe>', \"\")\n",
    "        .replace(\"\", \"\")\n",
    "    )\n",
    "    solution = re.sub(r\"frameBorder.*\\n\", \"\", solution)\n",
    "    solution = solution.replace('```\\n\"', \"```\\n\")\n",
    "\n",
    "    data[\"solution_md\"] = markdownify(solution)\n",
    "\n",
    "    approachs = solution.split(\"\\n---\\n\\n### Approach \")[1:]\n",
    "    data[\"approaches\"] = []\n",
    "    for i, approach in enumerate(approachs):\n",
    "        data[\"approaches\"].append(\n",
    "            {\n",
    "                \"title\": approach.split(\"\\n\")[0].replace(f\"{i+1}: \", \"\").strip(),\n",
    "                \"approach\": \"\\n\".join(approach.split(\"\\n\")[1:]).strip(),\n",
    "            }\n",
    "        )\n",
    "    with open(os.path.join(new_path, question), \"w\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "class OverallState(BaseModel):\n",
    "  input_message: str = Field(default=\"\")\n",
    "  middle_way: str = Field(default=\"\")\n",
    "\n",
    "g_sub = StateGraph(OverallState)\n",
    "g_sub.add_edge(START, \"node1\")\n",
    "g_sub.add_node(\"node1\", lambda state: {\"middle_way\": \"Hello \" + state.input_message})\n",
    "g_sub.add_edge(\"node1\", \"node2\")\n",
    "g_sub.add_node(\"node2\", lambda state: {\"middle_way\": \"\"})\n",
    "g_sub.add_edge(\"node2\", END)\n",
    "\n",
    "graph_sub = g_sub.compile(checkpointer=MemorySaver(), interrupt_after=[\"node1\"])\n",
    "\n",
    "g = StateGraph(OverallState)\n",
    "g.add_edge(START, \"graph_sub\")\n",
    "g.add_node(\"graph_sub\", graph_sub)\n",
    "g.add_edge(\"graph_sub\", END)\n",
    "\n",
    "graph = g.compile(checkpointer=MemorySaver(), interrupt_after=[\"graph_sub\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_middle_way:  .\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": 2}}\n",
    "\n",
    "output_middle_way = graph.invoke({\"input_message\": \"Minki\", \"middle_way\": \"\"}, config)\n",
    "print(\"output_middle_way:\", output_middle_way[\"middle_way\"], \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: {'input_message': 'Minki', 'middle_way': 'Hello Minki'}\n",
      "subgraph_config: {'configurable': {'thread_id': 2, 'checkpoint_ns': 'graph_sub:714c695b-910f-d279-3003-82357e5d3dc0', 'checkpoint_id': '1efaf7fe-9ab9-61d6-8001-3f0dc6992721', 'checkpoint_map': {'': '1efaf7fe-9aae-6772-8000-cce97e2c0395', 'graph_sub:714c695b-910f-d279-3003-82357e5d3dc0': '1efaf7fe-9ab9-61d6-8001-3f0dc6992721'}}}\n"
     ]
    }
   ],
   "source": [
    "state = graph.get_state(config, subgraphs=True)\n",
    "print(\"state:\", state.tasks[0].state.values)\n",
    "subgraph_config = state.tasks[0].state.config\n",
    "print(\"subgraph_config:\", subgraph_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_final:  .\n"
     ]
    }
   ],
   "source": [
    "output_final = graph.invoke(None, subgraph_config)\n",
    "print(\"output_final:\", output_final[\"middle_way\"], \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: ()\n",
      "state: <class 'tuple'>\n",
      "no tasks\n"
     ]
    }
   ],
   "source": [
    "state = graph.get_state(config, subgraphs=True)\n",
    "print(\"state:\", state.tasks)\n",
    "print(\"state:\", type(state.tasks))\n",
    "if not state.tasks:\n",
    "    print(\"no tasks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
